import json
import os
from collections import defaultdict

# 1. è¯»å–æ•°æ®æ–‡ä»¶
json_path = os.path.join("..", "assets", "data", "papers_data.json")

if not os.path.exists(json_path):
    print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {json_path}")
    exit()

with open(json_path, 'r', encoding='utf-8') as f:
    papers = json.load(f)

print(f"ğŸ“Š æ­£åœ¨æ£€æŸ¥ {len(papers)} ç¯‡è®ºæ–‡çš„é‡å¤æƒ…å†µ (æŒ‰é“¾æ¥æŸ¥é‡)...\n")

# 2. æŒ‰é“¾æ¥åˆ†ç»„
# Key: æ¸…æ´—åçš„é“¾æ¥, Value: å¯¹åº”çš„è®ºæ–‡å¯¹è±¡åˆ—è¡¨
link_map = defaultdict(list)

for p in papers:
    # å¿½ç•¥ https/http å·®å¼‚ï¼Œå¿½ç•¥æœ«å°¾æ–œæ 
    raw_link = p.get('link', '')
    clean_link = raw_link.replace('https://', '').replace('http://', '').rstrip('/')

    link_map[clean_link].append(p)

# 3. æ‰¾å‡ºé‡å¤é¡¹
dup_count = 0
for link, group in link_map.items():
    # å¦‚æœåŒä¸€ä¸ªé“¾æ¥å¯¹åº”äº†å¤šæ¡æ•°æ®ï¼Œè¯´æ˜æœ‰é‡å¤
    if len(group) > 1:
        dup_count += 1
        print(f"ğŸ”— å‘ç°é“¾æ¥é‡å¤ç»„ [å…± {len(group)} ç¯‡]:")
        print(f"   Link: {group[0]['link']}")
        print("   åˆ†åˆ«å¯¹åº”çš„æ ‡é¢˜:")
        for item in group:
            print(f"     âŒ {item['title']}")
        print("-" * 50)

# 4. æ€»ç»“
if dup_count == 0:
    print("âœ… å®Œç¾ï¼æ‰€æœ‰è®ºæ–‡çš„é“¾æ¥éƒ½æ˜¯å”¯ä¸€çš„ï¼Œæ²¡æœ‰é‡å¤ã€‚")
else:
    print(f"\nğŸš« å…±å‘ç° {dup_count} ç»„é‡å¤é“¾æ¥ã€‚")
    print("åŸå› ï¼šè¿™äº›è®ºæ–‡é“¾æ¥ç›¸åŒï¼Œä½†æ ‡é¢˜ä¸åŒï¼Œå¯¼è‡´è¢«'æ ‡é¢˜æŒ‡çº¹æ³•'å½“æˆäº†ä¸åŒçš„è®ºæ–‡ã€‚")